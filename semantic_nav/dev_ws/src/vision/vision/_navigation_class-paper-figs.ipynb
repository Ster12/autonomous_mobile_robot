{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from navigation import NavigationSystem\n",
    "from helpers import load_images_from_folder\n",
    "from semseg.util import config\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 24}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "mtx = np.array([[847.788207, 0.000000, 718.645947],\n",
    "[0.000000, 848.418915, 455.705157],\n",
    "[0.000000, 0.000000, 1.000000]])\n",
    "\n",
    "dist = np.array([[-0.332920, 0.089132, 0.001047, -0.002518, 0.000000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-04 20:34:17,945 INFO pspnet_segmentation.py line 62 3227] => loading checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:17,945 INFO pspnet_segmentation.py line 62 3227] => loading checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:17,945 INFO pspnet_segmentation.py line 62 3227] => loading checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:17,945 INFO pspnet_segmentation.py line 62 3227] => loading checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:17,945 INFO pspnet_segmentation.py line 62 3227] => loading checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:18,135 INFO pspnet_segmentation.py line 65 3227] => loaded checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:18,135 INFO pspnet_segmentation.py line 65 3227] => loaded checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:18,135 INFO pspnet_segmentation.py line 65 3227] => loaded checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:18,135 INFO pspnet_segmentation.py line 65 3227] => loaded checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:18,135 INFO pspnet_segmentation.py line 65 3227] => loaded checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n",
      "[2022-04-04 20:34:18,135 INFO pspnet_segmentation.py line 65 3227] => loaded checkpoint '/usr/src/app/pretrained_models/exp/ade20k/pspnet50/model/train_epoch_100.pth'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Object Detection\n",
      "Segmentation and Detection Models loaded, Testing the models\n",
      "Imgs tested\n",
      "Planner\n",
      "segmentation: 2.6630728244781494 seconds\n",
      "warp: 0.02073526382446289 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/dev_ws/src/vision/vision/helpers.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  scan_array = np.array(([scan_distances, scan_angles, scan_points])).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costmap: 0.04187440872192383 seconds\n",
      "planner_: 0.010094642639160156 seconds\n",
      "3.5015082359313965\n",
      "motion_control: 9.274482727050781e-05 seconds\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE = \"cfg/outdoor_pspnet50_navigation.yaml\"\n",
    "\n",
    "cfg = config.load_cfg_from_cfg_file(CONFIG_FILE)\n",
    "mtxs = np.load(cfg.perspective_transform_path)\n",
    "M_ = mtxs['M']\n",
    "M_inv_ = mtxs['M_inv']\n",
    "\n",
    "nav = NavigationSystem(cfg)\n",
    "img = cv2.imread(\"./data/outdoor1/left0417.jpg\")\n",
    "img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "dim = (cfg.original_width, cfg.original_height)\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "h,w,_ = img.shape\n",
    "start = time.time()\n",
    "path, result_img, result_top, segmented_img, drivable_img, cost_fwd, cost_obst, cost_center, cost, path_top_img, lines= nav.global_planner_step(img, None)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "# Local Planner\n",
    "robot_state = np.array([0.0,0.0,0.0])\n",
    "vel_cmd,yaw_rate_cmd = nav.local_planner_step(robot_state, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = './results/'\n",
    "# ========== Visual Summary ============\n",
    "# Segmentation\n",
    "drivable_added_img = cv2.addWeighted(img, 0.9, drivable_img, 0.8, 0)  \n",
    "cv2.imwrite(results_path+'00_seg_img.png',cv2.cvtColor(drivable_added_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Perspective\n",
    "drivable_added_top = cv2.warpPerspective(drivable_added_img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.imshow((drivable_added_top))\n",
    "ax.set_xlabel('Y[m]')\n",
    "ax.set_ylabel('X[m]')\n",
    "plt.xticks(np.arange(0, drivable_added_top.shape[0]+1,96), np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-96)/80.0,2))\n",
    "plt.yticks(np.arange(0, drivable_added_top.shape[0]+1,96), np.around(np.arange((drivable_added_top.shape[0]+1), 0,-96)/90.0,1))\n",
    "plt.savefig(results_path+'00_seg_top.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Costmap\n",
    "colormap = cv2.COLORMAP_HOT\n",
    "cost_heatmap = cv2.applyColorMap(np.uint8(255*cost/np.amax(cost)), colormap)\n",
    "# cost_heatmap = cv2.cvtColor(cost_heatmap, cv2.COLOR_BGR2RGB)\n",
    "axes = cv2.imread(\"./results/axes.png\")\n",
    "axes_img = cost_heatmap.copy()*0\n",
    "axes_img[480-62:480,(240-48-15):(240+48-15),:] = axes[0:62,:,:]\n",
    "# cost_heatmap = axes_img\n",
    "_,thresh1 = cv2.threshold(cv2.cvtColor(axes_img, cv2.COLOR_BGR2GRAY), 2,255,cv2.THRESH_BINARY_INV)\n",
    "thresh1 = np.uint8(thresh1/255)\n",
    "cost_heatmap[:,:,0]*=thresh1\n",
    "cost_heatmap[:,:,1]*=thresh1\n",
    "cost_heatmap[:,:,2]*=thresh1\n",
    "cost_heatmap+=axes_img\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.imshow(cv2.cvtColor(cost_heatmap, cv2.COLOR_BGR2RGB))\n",
    "ax.set_xlabel('Y[m]')\n",
    "ax.set_ylabel('X[m]')\n",
    "plt.xticks(np.arange(0, cost_heatmap.shape[0]+1,96), np.around(np.arange(cost_heatmap.shape[0]/2, -(cost_heatmap.shape[0]+1)/2,-96)/80.0,2))\n",
    "plt.yticks(np.arange(0, cost_heatmap.shape[0]+1,96), np.around(np.arange((cost_heatmap.shape[0]+1), 0,-96)/90.0,1))\n",
    "plt.savefig(results_path+'00_cost.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Paths\n",
    "cost_obst_heatmap = cv2.applyColorMap(np.uint8(255*cost_obst/np.amax(cost_obst)), colormap)\n",
    "img_top = cv2.warpPerspective(img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "img_top = cv2.cvtColor(img_top, cv2.COLOR_BGR2RGB)\n",
    "path_img = 0*cost_obst_heatmap.copy()\n",
    "x_idxs = np.uint16(path[:,0]*cfg.pixel_per_meter_x+cfg.width/2)\n",
    "y_idxs = -np.uint16(path[:,1]*cfg.pixel_per_meter_y-cfg.height)\n",
    "for i in range(x_idxs.shape[-1]-1):\n",
    "    path_img = cv2.line(path_img, (x_idxs[i],y_idxs[i]), (x_idxs[i+1],y_idxs[i+1]), (0, 255, 0), 3)  \n",
    "path_top = cv2.addWeighted(cost_obst_heatmap, 1.0, path_img, 0.7, 0) \n",
    "edge_lines_img = 0*cost_obst_heatmap.copy()\n",
    "lines = np.array(lines, dtype = np.int)\n",
    "for line in lines:\n",
    "    path_top = cv2.line(path_top, (line[0],line[1]), (line[2],line[3]), (255, 50, 50), 3)\n",
    "cv2.circle(path_top, (x_idxs[cfg.look_ahead], y_idxs[cfg.look_ahead]),10, (255, 255, 255), -1)\n",
    "cv2.putText(path_top, 'L', (x_idxs[cfg.look_ahead]+15, y_idxs[cfg.look_ahead]+0), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "path_top_added = cv2.addWeighted(img_top, 0.8, path_top, 1.0, 0)\n",
    "\n",
    "path_top_added[:,:,0]*=thresh1\n",
    "path_top_added[:,:,1]*=thresh1\n",
    "path_top_added[:,:,2]*=thresh1\n",
    "path_top_added+=axes_img\n",
    "\n",
    "fig, (ax, ax2) = plt.subplots(1,2,figsize=(20, 10),gridspec_kw={'width_ratios': [1, 1.335]})\n",
    "ax.imshow(cv2.cvtColor(path_top_added, cv2.COLOR_BGR2RGB))\n",
    "ax.set_xlabel('Y[m]')\n",
    "ax.set_ylabel('X[m]')\n",
    "\n",
    "ax.set_xticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "ax.set_xticklabels(np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-96)/80.0,2))\n",
    "ax.set_yticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "ax.set_yticklabels(np.around(np.arange((drivable_added_top.shape[0]+1), 0,-96)/90.0,1))\n",
    "\n",
    "path_top[:,:,0]*=thresh1\n",
    "path_top[:,:,1]*=thresh1\n",
    "path_top[:,:,2]*=thresh1\n",
    "path_top+=axes_img\n",
    "unwarped_path = cv2.warpPerspective(path_top, M_inv_, (w,h), flags=cv2.INTER_LINEAR)\n",
    "unwarped_path = cv2.cvtColor(unwarped_path, cv2.COLOR_BGR2RGB)\n",
    "path_added_img = cv2.addWeighted(img, 1.0, unwarped_path, 0.9, 0)\n",
    "path_top2 = cv2.resize(path_top, (h,h), interpolation = cv2.INTER_AREA)    \n",
    "ax2.imshow(path_added_img)\n",
    "ax2.axis('off')\n",
    "fig.tight_layout()\n",
    "plt.savefig(results_path+'00_path2.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.imshow(cv2.cvtColor(path_top_added, cv2.COLOR_BGR2RGB))\n",
    "ax.set_xlabel('Y[m]')\n",
    "ax.set_ylabel('X[m]')\n",
    "plt.xticks(np.arange(0, cost_obst_heatmap.shape[0]+1,96), np.around(np.arange(cost_obst_heatmap.shape[0]/2, -(cost_obst_heatmap.shape[0]+1)/2,-96)/cfg.pixel_per_meter_x,2))\n",
    "plt.yticks(np.arange(0, cost_obst_heatmap.shape[0]+1,96), np.around(np.arange((cost_obst_heatmap.shape[0]+1), 0,-96)/cfg.pixel_per_meter_y,1))\n",
    "plt.savefig(results_path+'00_path.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ========== Cost Maps ============\n",
    "cost_heatmap = cv2.applyColorMap(np.uint8(255*cost/np.amax(cost)), colormap)\n",
    "cost_heatmap[:,:,0]*=thresh1\n",
    "cost_heatmap[:,:,1]*=thresh1\n",
    "cost_heatmap[:,:,2]*=thresh1\n",
    "cost_heatmap+=axes_img\n",
    "cv2.imwrite(results_path+'00_cost_total.png',cost_heatmap)\n",
    "\n",
    "cost_fwd_heatmap = cv2.applyColorMap(np.uint8(255*cost_fwd/np.amax(cost_fwd)), colormap)\n",
    "cost_fwd_heatmap[:,:,0]*=thresh1\n",
    "cost_fwd_heatmap[:,:,1]*=thresh1\n",
    "cost_fwd_heatmap[:,:,2]*=thresh1\n",
    "cost_fwd_heatmap+=axes_img\n",
    "cv2.imwrite(results_path+'00_cost_fwd.png',cost_fwd_heatmap)\n",
    "\n",
    "cost_center_heatmap = cv2.applyColorMap(np.uint8(255*cost_center/np.amax(cost_center)), colormap)\n",
    "cost_center_heatmap[:,:,0]*=thresh1\n",
    "cost_center_heatmap[:,:,1]*=thresh1\n",
    "cost_center_heatmap[:,:,2]*=thresh1\n",
    "cost_center_heatmap+=axes_img\n",
    "cv2.imwrite(results_path+'00_cost_center.png',cost_center_heatmap)\n",
    "\n",
    "cost_obst_heatmap = cv2.applyColorMap(np.uint8(255*cost_obst/np.amax(cost_obst)), colormap)\n",
    "cost_obst_heatmap[:,:,0]*=thresh1\n",
    "cost_obst_heatmap[:,:,1]*=thresh1\n",
    "cost_obst_heatmap[:,:,2]*=thresh1\n",
    "cost_obst_heatmap+=axes_img\n",
    "cv2.imwrite(results_path+'00_cost_obst.png',cost_obst_heatmap)\n",
    "\n",
    "\n",
    "# cv2.imwrite(results_path+'00_cost.png',cost_heatmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple environments test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nav System\n",
    "CONFIG_FILE = \"cfg/gazebosim_fchardnet_navigation.yaml\"\n",
    "cfg = config.load_cfg_from_cfg_file(CONFIG_FILE)\n",
    "mtxs = np.load(cfg.perspective_transform_path)\n",
    "M_ = mtxs['M']\n",
    "M_inv_ = mtxs['M_inv']\n",
    "nav = NavigationSystem(cfg)\n",
    "\n",
    "# List of images\n",
    "img_names = [\n",
    "'0310.png',\n",
    "'0434.png',\n",
    "'0445.png',\n",
    "'0486.png',\n",
    "'0590.png',\n",
    "'0690.png',\n",
    "'0712.png',\n",
    "'0714.png',\n",
    "'0773.png',\n",
    "'0310.png',\n",
    "'0310.png',\n",
    "'0310.png',\n",
    "'0310.png',\n",
    "'0310.png',\n",
    "'0310.png',\n",
    "'0310.png'\n",
    "]\n",
    "sim_segmented_imgs = []\n",
    "sim_top_imgs = []\n",
    "sim_result_imgs= []\n",
    "sim_result_top_imgs= []\n",
    "\n",
    "for img_name in img_names:\n",
    "    img = cv2.imread(\"./data/sim/\"+img_name)\n",
    "#     img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    dim = (cfg.original_width, cfg.original_height)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h,w,_ = img.shape\n",
    "    path, result_img, result_top, segmented_img, drivable_img, cost_fwd, cost_obst, cost_center, cost, path_top_img, lines= nav.global_planner_step(img, None)\n",
    "    \n",
    "    # ======= Obtain visualizations ===========\n",
    "    # Segmented\n",
    "    drivable_added_img = cv2.addWeighted(img, 0.9, drivable_img, 0.8, 0) \n",
    "    sim_segmented_imgs.append(drivable_added_img)\n",
    "    \n",
    "    # Top View\n",
    "    drivable_added_top = cv2.warpPerspective(drivable_added_img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "    drivable_added_top2 = cv2.resize(drivable_added_top, (h,h), interpolation = cv2.INTER_AREA) \n",
    "    sim_top_imgs.append(drivable_added_top)\n",
    "\n",
    "    # Results\n",
    "    colormap = cv2.COLORMAP_HOT\n",
    "    cost_heatmap = cv2.applyColorMap(np.uint8(255*cost/np.amax(cost)), colormap)\n",
    "    cost_heatmap = cv2.cvtColor(cost_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_fwd_heatmap = cv2.applyColorMap(np.uint8(255*cost_fwd/np.amax(cost_fwd)), colormap)\n",
    "    cost_fwd_heatmap = cv2.cvtColor(cost_fwd_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_center_heatmap = cv2.applyColorMap(np.uint8(255*cost_center/np.amax(cost_center)), colormap)\n",
    "    cost_center_heatmap = cv2.cvtColor(cost_center_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_obst_heatmap = cv2.applyColorMap(np.uint8(255*cost_obst/np.amax(cost_obst)), colormap)\n",
    "    cost_obst_heatmap = cv2.cvtColor(cost_obst_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Paths\n",
    "    path_img = 0*cost_heatmap.copy()\n",
    "    x_idxs = np.uint16(path[:,0]*cfg.pixel_per_meter_x+cfg.width/2)\n",
    "    y_idxs = -np.uint16(path[:,1]*cfg.pixel_per_meter_y-cfg.height)\n",
    "    for i in range(x_idxs.shape[-1]-1):\n",
    "        path_img = cv2.line(path_img, (x_idxs[i],y_idxs[i]), (x_idxs[i+1],y_idxs[i+1]), (0, 255, 0), 3)  \n",
    "    path_top = cv2.addWeighted(cost_obst_heatmap, 0.5, path_img, 2.0, 0) \n",
    "    edge_lines_img = 0*cost_heatmap.copy()\n",
    "    if lines is not None:\n",
    "        lines = np.array(lines, dtype = np.int)\n",
    "        for line in lines:\n",
    "            path_top = cv2.line(path_top, (line[0],line[1]), (line[2],line[3]), (50, 50, 255), 3)\n",
    "    path_top_added = cv2.addWeighted(img_top, 0.8, path_top, 1.0, 0)\n",
    "    \n",
    "    cv2.circle(path_top, (x_idxs[cfg.look_ahead], y_idxs[cfg.look_ahead]),10, (255, 255, 255), -1)\n",
    "    cv2.putText(path_top, 'L', (x_idxs[cfg.look_ahead]+15, y_idxs[cfg.look_ahead]+0), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    axes = cv2.imread(\"./results/axes.png\")\n",
    "    axes_img = cost_heatmap.copy()*0\n",
    "    axes_img[480-62:480,(240-48-15):(240+48-15),:] = axes[0:62,:,:]\n",
    "    # cost_heatmap = axes_img\n",
    "    _,thresh1 = cv2.threshold(cv2.cvtColor(axes_img, cv2.COLOR_BGR2GRAY), 2,255,cv2.THRESH_BINARY_INV)\n",
    "    thresh1 = np.uint8(thresh1/255)\n",
    "    path_top[:,:,0]*=thresh1\n",
    "    path_top[:,:,1]*=thresh1\n",
    "    path_top[:,:,2]*=thresh1\n",
    "    path_top+=cv2.cvtColor(axes_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    path_top_added[:,:,0]*=thresh1\n",
    "    path_top_added[:,:,1]*=thresh1\n",
    "    path_top_added[:,:,2]*=thresh1\n",
    "    path_top_added+=cv2.cvtColor(axes_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    unwarped_path = cv2.warpPerspective(path_top, M_inv_, (w,h), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    path_added_img = cv2.addWeighted(img, 1.0, unwarped_path, 0.9, 0)\n",
    "    \n",
    "    path_top2 = cv2.resize(path_top, (h,h), interpolation = cv2.INTER_AREA)    \n",
    "#     path_added_img = cv2.hconcat([path_top2, path_added_img])\n",
    "    sim_result_top_imgs.append(path_top_added)\n",
    "    sim_result_imgs.append(path_added_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nav System\n",
    "CONFIG_FILE = \"cfg/outdoor_pspnet50_navigation.yaml\"\n",
    "cfg = config.load_cfg_from_cfg_file(CONFIG_FILE)\n",
    "mtxs = np.load(cfg.perspective_transform_path)\n",
    "M_ = mtxs['M']\n",
    "M_inv_ = mtxs['M_inv']\n",
    "nav = NavigationSystem(cfg)\n",
    "\n",
    "# List of images\n",
    "img_names = ['left0155.jpg',\n",
    "'left0223.jpg',\n",
    "'left0337.jpg',\n",
    "'left0417.jpg',\n",
    "'left0562.jpg',\n",
    "'left0663.jpg',\n",
    "'left0666.jpg',\n",
    "'left0786.jpg',\n",
    "'left1055.jpg',\n",
    "'left1069.jpg',\n",
    "'left1080.jpg',\n",
    "'left1199.jpg',\n",
    "'left1292.jpg',\n",
    "'left1390.jpg',\n",
    "'left1487.jpg'\n",
    "            ]\n",
    "out_segmented_imgs = []\n",
    "out_top_imgs = []\n",
    "out_result_imgs= []\n",
    "out_result_top_imgs= []\n",
    "\n",
    "for img_name in img_names:\n",
    "    img = cv2.imread(\"./data/outdoor1/\"+img_name)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    dim = (cfg.original_width, cfg.original_height)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h,w,_ = img.shape\n",
    "    path, result_img, result_top, segmented_img, drivable_img, cost_fwd, cost_obst, cost_center, cost, path_top_img, lines= nav.global_planner_step(img, None)\n",
    "    \n",
    "    # ======= Obtain visualizations ===========\n",
    "    # Segmented\n",
    "    drivable_added_img = cv2.addWeighted(img, 0.9, drivable_img, 0.8, 0) \n",
    "    out_segmented_imgs.append(drivable_added_img)\n",
    "    \n",
    "    # Top View\n",
    "    drivable_added_top = cv2.warpPerspective(drivable_added_img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "    drivable_added_top2 = cv2.resize(drivable_added_top, (h,h), interpolation = cv2.INTER_AREA) \n",
    "    out_top_imgs.append(drivable_added_top)\n",
    "\n",
    "    # Results\n",
    "    colormap = cv2.COLORMAP_HOT\n",
    "    cost_heatmap = cv2.applyColorMap(np.uint8(255*cost/np.amax(cost)), colormap)\n",
    "    cost_heatmap = cv2.cvtColor(cost_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_fwd_heatmap = cv2.applyColorMap(np.uint8(255*cost_fwd/np.amax(cost_fwd)), colormap)\n",
    "    cost_fwd_heatmap = cv2.cvtColor(cost_fwd_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_center_heatmap = cv2.applyColorMap(np.uint8(255*cost_center/np.amax(cost_center)), colormap)\n",
    "    cost_center_heatmap = cv2.cvtColor(cost_center_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_obst_heatmap = cv2.applyColorMap(np.uint8(255*cost_obst/np.amax(cost_obst)), colormap)\n",
    "    cost_obst_heatmap = cv2.cvtColor(cost_obst_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Paths\n",
    "    path_img = 0*cost_heatmap.copy()\n",
    "    x_idxs = np.uint16(path[:,0]*cfg.pixel_per_meter_x+cfg.width/2)\n",
    "    y_idxs = -np.uint16(path[:,1]*cfg.pixel_per_meter_y-cfg.height)\n",
    "    for i in range(x_idxs.shape[-1]-1):\n",
    "        path_img = cv2.line(path_img, (x_idxs[i],y_idxs[i]), (x_idxs[i+1],y_idxs[i+1]), (0, 255, 0), 3)  \n",
    "    path_top = cv2.addWeighted(cost_obst_heatmap, 0.7, path_img, 2.0, 0) \n",
    "    \n",
    "    edge_lines_img = 0*cost_heatmap.copy()\n",
    "    if lines is not None:\n",
    "        lines = np.array(lines, dtype = np.int)\n",
    "        for line in lines:\n",
    "            path_top = cv2.line(path_top, (line[0],line[1]), (line[2],line[3]), (50, 50, 255), 3)\n",
    "    path_top_added = cv2.addWeighted(img_top, 0.8, path_top, 1.0, 0)\n",
    "    \n",
    "    cv2.circle(path_top, (x_idxs[cfg.look_ahead], y_idxs[cfg.look_ahead]),10, (255, 255, 255), -1)\n",
    "    cv2.putText(path_top, 'L', (x_idxs[cfg.look_ahead]+15, y_idxs[cfg.look_ahead]+0), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    axes = cv2.imread(\"./results/axes.png\")\n",
    "    axes_img = cost_heatmap.copy()*0\n",
    "    axes_img[480-62:480,(240-48-15):(240+48-15),:] = axes[0:62,:,:]\n",
    "    # cost_heatmap = axes_img\n",
    "    _,thresh1 = cv2.threshold(cv2.cvtColor(axes_img, cv2.COLOR_BGR2GRAY), 2,255,cv2.THRESH_BINARY_INV)\n",
    "    thresh1 = np.uint8(thresh1/255)\n",
    "    path_top[:,:,0]*=thresh1\n",
    "    path_top[:,:,1]*=thresh1\n",
    "    path_top[:,:,2]*=thresh1\n",
    "    path_top+=cv2.cvtColor(axes_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    path_top_added[:,:,0]*=thresh1\n",
    "    path_top_added[:,:,1]*=thresh1\n",
    "    path_top_added[:,:,2]*=thresh1\n",
    "    path_top_added+=cv2.cvtColor(axes_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    unwarped_path = cv2.warpPerspective(path_top, M_inv_, (w,h), flags=cv2.INTER_LINEAR)\n",
    "    path_added_img = cv2.addWeighted(img, 0.8, unwarped_path, 1.0, 0)\n",
    "    \n",
    "    path_top2 = cv2.resize(path_top, (h,h), interpolation = cv2.INTER_AREA)    \n",
    "#     path_added_img = cv2.hconcat([path_top2, path_added_img])\n",
    "    out_result_top_imgs.append(path_top_added)\n",
    "    out_result_imgs.append(path_added_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nav System\n",
    "CONFIG_FILE = \"cfg/indoor_pspnet50_navigation.yaml\"\n",
    "cfg = config.load_cfg_from_cfg_file(CONFIG_FILE)\n",
    "mtxs = np.load(cfg.perspective_transform_path)\n",
    "M_ = mtxs['M']\n",
    "M_inv_ = mtxs['M_inv']\n",
    "nav = NavigationSystem(cfg)\n",
    "\n",
    "# List of images\n",
    "img_names = ['indoor1/left0117.jpg',\n",
    "'indoor1/left0166.jpg',\n",
    "'indoor1/left0176.jpg',\n",
    "'indoor1/left0259.jpg',\n",
    "'indoor1/left0263.jpg',\n",
    "'indoor1/left0598.jpg',\n",
    "'indoor1/left0677.jpg',\n",
    "'indoor1/left0685.jpg',\n",
    "'indoor1/left1487.jpg',\n",
    "'indoor2/left0120.jpg',\n",
    "'indoor2/left0135.jpg',\n",
    "'indoor2/left0131.jpg',\n",
    "'indoor2/left0257.jpg',\n",
    "'indoor2/left0272.jpg',\n",
    "'indoor2/left0440.jpg',\n",
    "'indoor2/left0715.jpg']\n",
    "\n",
    "in_segmented_imgs = []\n",
    "in_top_imgs = []\n",
    "in_result_imgs= []\n",
    "in_result_top_imgs= []\n",
    "\n",
    "for img_name in img_names:\n",
    "    img = cv2.imread(\"./data/\"+img_name)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    dim = (cfg.original_width, cfg.original_height)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    path, result_img, result_top, segmented_img, drivable_img, cost_fwd, cost_obst, cost_center, cost, path_top_img, lines= nav.global_planner_step(img, None)\n",
    "    \n",
    "    # ======= Obtain visualizations ===========\n",
    "    # Segmented\n",
    "    drivable_added_img = cv2.addWeighted(img, 0.9, drivable_img, 0.8, 0) \n",
    "    in_segmented_imgs.append(drivable_added_img)\n",
    "    \n",
    "    # Top View\n",
    "    drivable_added_top = cv2.warpPerspective(drivable_added_img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "    drivable_added_top2 = cv2.resize(drivable_added_top, (h,h), interpolation = cv2.INTER_AREA) \n",
    "    in_top_imgs.append(drivable_added_top)\n",
    "\n",
    "    # Results\n",
    "    colormap = cv2.COLORMAP_HOT\n",
    "    cost_heatmap = cv2.applyColorMap(np.uint8(255*cost/np.amax(cost)), colormap)\n",
    "    cost_heatmap = cv2.cvtColor(cost_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_fwd_heatmap = cv2.applyColorMap(np.uint8(255*cost_fwd/np.amax(cost_fwd)), colormap)\n",
    "    cost_fwd_heatmap = cv2.cvtColor(cost_fwd_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_center_heatmap = cv2.applyColorMap(np.uint8(255*cost_center/np.amax(cost_center)), colormap)\n",
    "    cost_center_heatmap = cv2.cvtColor(cost_center_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cost_obst_heatmap = cv2.applyColorMap(np.uint8(255*cost_obst/np.amax(cost_obst)), colormap)\n",
    "    cost_obst_heatmap = cv2.cvtColor(cost_obst_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Paths\n",
    "    path_img = 0*cost_heatmap.copy()\n",
    "    x_idxs = np.uint16(path[:,0]*cfg.pixel_per_meter_x+cfg.width/2)\n",
    "    y_idxs = -np.uint16(path[:,1]*cfg.pixel_per_meter_y-cfg.height)\n",
    "    for i in range(x_idxs.shape[-1]-1):\n",
    "        path_img = cv2.line(path_img, (x_idxs[i],y_idxs[i]), (x_idxs[i+1],y_idxs[i+1]), (0, 255, 0), 3)  \n",
    "    path_top = cv2.addWeighted(cost_obst_heatmap, 0.8, path_img, 2.0, 0) \n",
    "    \n",
    "    edge_lines_img = 0*cost_heatmap.copy()\n",
    "    lines = np.array(lines, dtype = np.int)\n",
    "    for line in lines:\n",
    "        path_top = cv2.line(path_top, (line[0],line[1]), (line[2],line[3]), (50, 50, 255), 3)\n",
    "    path_top_added = cv2.addWeighted(img_top, 0.8, path_top, 0.9, 0)\n",
    "    \n",
    "    \n",
    "    if(x_idxs.shape[-1] > cfg.look_ahead):\n",
    "        ix = x_idxs[cfg.look_ahead]\n",
    "        iy = y_idxs[cfg.look_ahead]\n",
    "    else:\n",
    "        ix = x_idxs[-1]\n",
    "        iy = y_idxs[-1]\n",
    "    cv2.circle(path_top, (ix, iy),10, (255, 255, 255), -1)\n",
    "    cv2.putText(path_top, 'L', (ix+15, iy+0), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    axes = cv2.imread(\"./results/axes.png\")\n",
    "    axes_img = cost_heatmap.copy()*0\n",
    "    axes_img[480-62:480,(240-48-15):(240+48-15),:] = axes[0:62,:,:]\n",
    "    # cost_heatmap = axes_img\n",
    "    _,thresh1 = cv2.threshold(cv2.cvtColor(axes_img, cv2.COLOR_BGR2GRAY), 2,255,cv2.THRESH_BINARY_INV)\n",
    "    thresh1 = np.uint8(thresh1/255)\n",
    "    path_top[:,:,0]*=thresh1\n",
    "    path_top[:,:,1]*=thresh1\n",
    "    path_top[:,:,2]*=thresh1\n",
    "    path_top+=cv2.cvtColor(axes_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    \n",
    "    path_top_added[:,:,0]*=thresh1\n",
    "    path_top_added[:,:,1]*=thresh1\n",
    "    path_top_added[:,:,2]*=thresh1\n",
    "    path_top_added+=cv2.cvtColor(axes_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    unwarped_path = cv2.warpPerspective(path_top, M_inv_, (w,h), flags=cv2.INTER_LINEAR)\n",
    "    path_added_img = cv2.addWeighted(img, 1.0, unwarped_path, 0.9, 0)\n",
    "    \n",
    "    path_top2 = cv2.resize(path_top, (h,h), interpolation = cv2.INTER_AREA)    \n",
    "#     path_added_img = cv2.hconcat([path_top2, path_added_img])\n",
    "    in_result_top_imgs.append(path_top_added)\n",
    "    in_result_imgs.append(path_added_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures\n",
    "## Segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top view\n",
    "import matplotlib\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 26}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# # segmented imgs\n",
    "out_idxs = [3,5,6,12,12]\n",
    "in_idxs = [3,4,6,7,14]\n",
    "sim_idxs = [1,4,5,7,14]\n",
    "\n",
    "out_idxs = [9]\n",
    "in_idxs = [13]\n",
    "sim_idxs = [1]\n",
    "\n",
    "f, axs = plt.subplots(1, 3,figsize=(20,26))\n",
    "axs = [axs]\n",
    "for i,ax in enumerate(axs):\n",
    "    ax[0].imshow(out_segmented_imgs[out_idxs[i]])\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Outdoor')\n",
    "    ax[1].imshow(in_segmented_imgs[in_idxs[i]])\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Indoor')\n",
    "    sim_segmented_imgs[sim_idxs[i]] = cv2.resize(sim_segmented_imgs[sim_idxs[i]], dim, interpolation = cv2.INTER_AREA)\n",
    "    ax[2].imshow(sim_segmented_imgs[sim_idxs[i]])\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('Simulation')\n",
    "fig.tight_layout()\n",
    "plt.savefig(results_path+'01_semantic.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f, axs = plt.subplots(3, 2,figsize=(20,24),gridspec_kw={'width_ratios': [1.335, 1]})\n",
    "axs[0][1].imshow(out_top_imgs[3])\n",
    "axs[0][1].set_xlabel('Y[m]')\n",
    "axs[0][1].set_ylabel('X[m]')\n",
    "axs[0][1].set_title('Top-Down-View')\n",
    "axs[0][1].set_xticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "axs[0][1].set_xticklabels(np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-96)/80.0,2))\n",
    "axs[0][1].set_yticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "axs[0][1].set_yticklabels(np.around(np.arange((drivable_added_top.shape[0]+1), 0,-96)/90.0,1))\n",
    "print(out_top_imgs[3].shape)\n",
    "axs[0][0].imshow(out_segmented_imgs[3])\n",
    "axs[0][0].axis('off')\n",
    "axs[0][0].set_title('Drivable Area')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs[1][1].imshow(in_top_imgs[4])\n",
    "axs[1][1].set_xlabel('Y[m]')\n",
    "axs[1][1].set_ylabel('X[m]')\n",
    "axs[1][1].set_xticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "axs[1][1].set_xticklabels(np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-96)/80.0,2))\n",
    "axs[1][1].set_yticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "axs[1][1].set_yticklabels(np.around(np.arange((drivable_added_top.shape[0]+1), 0,-96)/90.0,1))\n",
    "axs[1][0].imshow(in_segmented_imgs[4])\n",
    "axs[1][0].axis('off')\n",
    "\n",
    "axs[2][1].imshow(sim_top_imgs[4])\n",
    "axs[2][1].set_xlabel('Y[m]')\n",
    "axs[2][1].set_ylabel('X[m]')\n",
    "axs[2][1].set_xticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "axs[2][1].set_xticklabels(np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-96)/60.0,2))\n",
    "axs[2][1].set_yticks(np.arange(0, drivable_added_top.shape[0]+1,96)) \n",
    "axs[2][1].set_yticklabels(np.around(np.arange((drivable_added_top.shape[0]+1), 0,-96)/70.0,1))\n",
    "sim_segmented_imgs[4] = cv2.resize(sim_segmented_imgs[4], dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "axs[2][0].imshow(sim_segmented_imgs[4])\n",
    "axs[2][0].axis('off')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.07, \n",
    "                    hspace=0.17)\n",
    "fig.tight_layout()\n",
    "plt.savefig(results_path+'01_perspective.png',dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 28}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "# # segmented imgs\n",
    "out_idxs = [3,6,13,4,5]\n",
    "in_idxs = [13,6,7,14,4]\n",
    "sim_idxs = [4,1,5,7,14]\n",
    "# results\n",
    "\n",
    "f, axs = plt.subplots(3, 5,figsize=(24,12))\n",
    "for i in range(5):\n",
    "    axs[0][i].imshow(out_result_imgs[out_idxs[i]])\n",
    "    axs[0][i].set_xticks([]) \n",
    "    axs[0][i].set_yticks([]) \n",
    "\n",
    "for i in range(5):\n",
    "    axs[1][i].imshow(in_result_imgs[in_idxs[i]])\n",
    "    axs[1][i].set_xticks([]) \n",
    "    axs[1][i].set_yticks([]) \n",
    "    \n",
    "for i in range(5):\n",
    "    sim_result_imgs[sim_idxs[i]] = cv2.resize(sim_result_imgs[sim_idxs[i]], dim, interpolation = cv2.INTER_AREA)\n",
    "    axs[2][i].imshow(sim_result_imgs[sim_idxs[i]])\n",
    "    axs[2][i].set_xticks([]) \n",
    "    axs[2][i].set_yticks([]) \n",
    "\n",
    "axs[0][0].set_ylabel('Outdoor')\n",
    "axs[1][0].set_ylabel('Indoor')\n",
    "axs[2][0].set_ylabel('Simulation')\n",
    "\n",
    "    \n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.1)\n",
    "fig.tight_layout()\n",
    "plt.savefig(results_path+'01_results.png',dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# f, axs = plt.subplots(5, 3,figsize=(28,35))\n",
    "# for i,ax in enumerate(axs):\n",
    "#     ax[0].imshow(out_result_imgs[out_idxs[i]])\n",
    "#     ax[0].axis('off')\n",
    "#     ax[1].imshow(in_result_imgs[in_idxs[i]])\n",
    "#     ax[1].axis('off')\n",
    "#     ax[2].imshow(sim_result_imgs[sim_idxs[i]])\n",
    "#     ax[2].axis('off')\n",
    "    \n",
    "# plt.subplots_adjust(left=0.1,\n",
    "#                     bottom=0.1, \n",
    "#                     right=0.9, \n",
    "#                     top=0.9, \n",
    "#                     wspace=0.1, \n",
    "#                     hspace=0.1)\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### # results\n",
    "f, axs = plt.subplots(15, 3,figsize=(28,110))\n",
    "for i,ax in enumerate(axs):\n",
    "    ax[0].imshow(out_result_imgs[i])\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(in_result_imgs[i])\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(sim_result_imgs[i])\n",
    "    ax[2].axis('off')\n",
    "    \n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.1)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top view\n",
    "f, axs = plt.subplots(3, 2,figsize=(20,18),gridspec_kw={'width_ratios': [1.335, 1]})\n",
    "axs[0][1].imshow(out_top_imgs[3])\n",
    "axs[0][1].set_xlabel('Y[m]')\n",
    "axs[0][1].set_ylabel('X[m]')\n",
    "# plt.xticks(np.arange(0, drivable_added_top.shape[0]+1,48), np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-48)/80.0,2))\n",
    "# plt.yticks(np.arange(0, drivable_added_top.shape[0]+1,48), np.around(np.arange((drivable_added_top.shape[0]+1), 0,-48)/90.0,1))\n",
    "axs[0][0].imshow(out_segmented_imgs[3])\n",
    "axs[0][0].axis('off')\n",
    "\n",
    "axs[1][1].imshow(in_top_imgs[4])\n",
    "axs[1][1].set_xlabel('Y[m]')\n",
    "axs[1][1].set_ylabel('X[m]')\n",
    "# plt.xticks(np.arange(0, drivable_added_top.shape[0]+1,48), np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-48)/80.0,2))\n",
    "# plt.yticks(np.arange(0, drivable_added_top.shape[0]+1,48), np.around(np.arange((drivable_added_top.shape[0]+1), 0,-48)/90.0,1))\n",
    "axs[1][0].imshow(in_segmented_imgs[4])\n",
    "axs[1][0].axis('off')\n",
    "\n",
    "axs[2][1].imshow(sim_top_imgs[4])\n",
    "axs[2][1].set_xlabel('Y[m]')\n",
    "axs[2][1].set_ylabel('X[m]')\n",
    "# plt.xticks(np.arange(0, drivable_added_top.shape[0]+1,48), np.around(np.arange(drivable_added_top.shape[0]/2, -(drivable_added_top.shape[0]+1)/2,-48)/80.0,2))\n",
    "# plt.yticks(np.arange(0, drivable_added_top.shape[0]+1,48), np.around(np.arange((drivable_added_top.shape[0]+1), 0,-48)/90.0,1))\n",
    "axs[2][0].imshow(sim_segmented_imgs[4])\n",
    "axs[2][0].axis('off')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # segmented imgs\n",
    "f, axs = plt.subplots(15, 3,figsize=(20,120))\n",
    "for i,ax in enumerate(axs):\n",
    "    ax[0].imshow(out_segmented_imgs[i])\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(in_segmented_imgs[i])\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(sim_segmented_imgs[i])\n",
    "    ax[2].axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Create visualizations ===== #\n",
    "# Segmentation\n",
    "drivable_added_img = cv2.addWeighted(img, 0.7, drivable_img, 0.9, 0)  \n",
    "segmented_added_img = cv2.addWeighted(img, 1.0, segmented_img, 0.5, 0) \n",
    "\n",
    "\n",
    "\n",
    "# Perspective Transformation\n",
    "img_top = cv2.warpPerspective(img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "drivable_top = cv2.warpPerspective(drivable_img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "drivable_added_top = cv2.warpPerspective(drivable_added_img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "segmented_added_top = cv2.warpPerspective(segmented_added_img, M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "drivable_top2 = cv2.resize(drivable_top, (h,h), interpolation = cv2.INTER_AREA)  \n",
    "drivable_added_top2 = cv2.resize(drivable_added_top, (h,h), interpolation = cv2.INTER_AREA) \n",
    "segmented_added_top2 = cv2.resize(segmented_added_top, (h,h), interpolation = cv2.INTER_AREA)    \n",
    "\n",
    "\n",
    "drivable_top_concat = cv2.hconcat([drivable_added_img, drivable_top2])\n",
    "drivable_addedtop_concat = cv2.hconcat([drivable_added_img, drivable_added_top2])\n",
    "segmented_addedtop_concat = cv2.hconcat([segmented_added_img, segmented_added_top2])\n",
    "\n",
    "\n",
    "\n",
    "# Costmaps\n",
    "colormap = cv2.COLORMAP_HOT\n",
    "cost_heatmap = cv2.applyColorMap(np.uint8(255*cost/np.amax(cost)), colormap)\n",
    "cost_heatmap = cv2.cvtColor(cost_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cost_fwd_heatmap = cv2.applyColorMap(np.uint8(255*cost_fwd/np.amax(cost_fwd)), colormap)\n",
    "cost_fwd_heatmap = cv2.cvtColor(cost_fwd_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cost_center_heatmap = cv2.applyColorMap(np.uint8(255*cost_center/np.amax(cost_center)), colormap)\n",
    "cost_center_heatmap = cv2.cvtColor(cost_center_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cost_obst_heatmap = cv2.applyColorMap(np.uint8(255*cost_obst/np.amax(cost_obst)), colormap)\n",
    "cost_obst_heatmap = cv2.cvtColor(cost_obst_heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Paths\n",
    "path_img = 0*cost_heatmap.copy()\n",
    "x_idxs = np.uint16(path[:,0]*cfg.pixel_per_meter_x+cfg.width/2)\n",
    "y_idxs = -np.uint16(path[:,1]*cfg.pixel_per_meter_y-cfg.height)\n",
    "for i in range(x_idxs.shape[-1]-1):\n",
    "    path_img = cv2.line(path_img, (x_idxs[i],y_idxs[i]), (x_idxs[i+1],y_idxs[i+1]), (50, 255, 50), 3)  \n",
    "path_top = cv2.addWeighted(cost_obst_heatmap, 1.0, path_img, 0.7, 0) \n",
    "edge_lines_img = 0*cost_heatmap.copy()\n",
    "lines = np.array(lines, dtype = np.int)\n",
    "for line in lines:\n",
    "    path_top = cv2.line(path_top, (line[0],line[1]), (line[2],line[3]), (50, 50, 255), 3)\n",
    "path_top_added = cv2.addWeighted(img_top, 0.8, path_top, 1.0, 0)\n",
    "\n",
    "unwarped_path = cv2.warpPerspective(path_top, M_inv_, (w,h), flags=cv2.INTER_LINEAR)\n",
    "path_added_img = cv2.addWeighted(img, 0.8, unwarped_path, 1.0, 0)\n",
    "\n",
    "path_top2 = cv2.resize(path_top, (h,h), interpolation = cv2.INTER_AREA)    \n",
    "path_added_img = cv2.hconcat([path_top2, path_added_img])\n",
    "\n",
    "\n",
    "# x_idxs = path[:,0]*cfg.pixel_per_meter_x+cfg.width/2\n",
    "# y_idxs = -(path[:,1]*cfg.pixel_per_meter_y-cfg.height)\n",
    "# ax.plot(x_idxs,y_idxs, color='greenyellow', linewidth=4)\n",
    "\n",
    "#seg\n",
    "plt.imshow(segmented_added_img)\n",
    "plt.show()\n",
    "\n",
    "#perspective\n",
    "plt.imshow(drivable_top_concat)\n",
    "plt.show()\n",
    "plt.imshow(drivable_addedtop_concat)\n",
    "plt.show()\n",
    "plt.imshow(segmented_addedtop_concat)\n",
    "plt.show()\n",
    "\n",
    "#cost\n",
    "plt.imshow(cost_obst_heatmap)\n",
    "plt.show()\n",
    "plt.imshow(cost_fwd_heatmap)\n",
    "plt.show()\n",
    "plt.imshow(cost_center_heatmap)\n",
    "plt.show()\n",
    "plt.imshow(cost_heatmap)\n",
    "plt.show()\n",
    "\n",
    "#path\n",
    "plt.imshow(path_top_added)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(path_added_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, filenames = load_images_from_folder('./data/indoor2/')\n",
    "print('processing {} images'.format(len(imgs)))\n",
    "i=0\n",
    "start = time.time()\n",
    "\n",
    "for img, filename in zip(imgs, filenames):\n",
    "    print('===============File: {} ============'.format(filename))\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    path, result_img, result_birdview, segmented_img = nav.global_planner_step(img, None)\n",
    "    \n",
    "    h,w,_ = result_img.shape\n",
    "    result_birdview = cv2.resize(result_birdview, (h,h), interpolation = cv2.INTER_AREA)\n",
    "    segmented_img = cv2.resize(segmented_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concat = cv2.hconcat([segmented_img, result_img, result_birdview])\n",
    "#     fig, ax = plt.subplots(figsize=(14, 7))\n",
    "#     ax.imshow(concat)\n",
    "#     plt.show()   \n",
    "    concat = cv2.cvtColor(concat, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imwrite('./output/indoor2/{}'.format(filename), concat)\n",
    "    i = i+1\n",
    "end = time.time()\n",
    "print('avg time: {}'.format((end-start)/len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, filenames = load_images_from_folder('./data/indoor1/')\n",
    "print('processing {} images'.format(len(imgs)))\n",
    "i=0\n",
    "start = time.time()\n",
    "\n",
    "for img, filename in zip(imgs, filenames):\n",
    "    print('===============File: {} ============'.format(filename))\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    path, result_img, result_birdview, segmented_img = nav.global_planner_step(img, None)\n",
    "    \n",
    "    h,w,_ = result_img.shape\n",
    "    result_birdview = cv2.resize(result_birdview, (h,h), interpolation = cv2.INTER_AREA)\n",
    "    segmented_img = cv2.resize(segmented_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concat = cv2.hconcat([segmented_img, result_img, result_birdview])\n",
    "#     fig, ax = plt.subplots(figsize=(14, 7))\n",
    "#     ax.imshow(concat)\n",
    "#     plt.show()   \n",
    "    concat = cv2.cvtColor(concat, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imwrite('./output/indoor1/{}'.format(filename), concat)\n",
    "    i = i+1\n",
    "end = time.time()\n",
    "print('avg time: {}'.format((end-start)/len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"cfg/indoor_pspnet50_navigation.yaml\"\n",
    "cfg = config.load_cfg_from_cfg_file(CONFIG_FILE)\n",
    "nav = NavigationSystem(cfg)\n",
    "imgs, filenames = load_images_from_folder('./data/indoor1/')\n",
    "print('processing {} images'.format(len(imgs)))\n",
    "i=0\n",
    "start = time.time()\n",
    "\n",
    "for img, filename in zip(imgs, filenames):\n",
    "    print('===============File: {} ============'.format(filename))\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    path, result_img, result_birdview, segmented_img = nav.global_planner_step(img, None)\n",
    "    \n",
    "    h,w,_ = result_img.shape\n",
    "    result_birdview = cv2.resize(result_birdview, (h,h), interpolation = cv2.INTER_AREA)\n",
    "    segmented_img = cv2.resize(segmented_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concat = cv2.hconcat([segmented_img, result_img, result_birdview])\n",
    "#     fig, ax = plt.subplots(figsize=(14, 7))\n",
    "#     ax.imshow(concat)\n",
    "#     plt.show()   \n",
    "    concat = cv2.cvtColor(concat, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imwrite('./output/indoor1/{}'.format(filename), concat)\n",
    "    i = i+1\n",
    "end = time.time()\n",
    "print('avg time: {}'.format((end-start)/len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, filenames = load_images_from_folder('./data/indoor2/')\n",
    "print('processing {} images'.format(len(imgs)))\n",
    "i=0\n",
    "start = time.time()\n",
    "\n",
    "for img, filename in zip(imgs, filenames):\n",
    "    print('===============File: {} ============'.format(filename))\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    path, result_img, result_birdview, segmented_img = nav.global_planner_step(img, None)\n",
    "    \n",
    "    h,w,_ = result_img.shape\n",
    "    result_birdview = cv2.resize(result_birdview, (h,h), interpolation = cv2.INTER_AREA)\n",
    "    segmented_img = cv2.resize(segmented_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concat = cv2.hconcat([segmented_img, result_img, result_birdview])\n",
    "#     fig, ax = plt.subplots(figsize=(14, 7))\n",
    "#     ax.imshow(concat)\n",
    "#     plt.show()   \n",
    "    concat = cv2.cvtColor(concat, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imwrite('./output/indoor2/{}'.format(filename), concat)\n",
    "    i = i+1\n",
    "end = time.time()\n",
    "print('avg time: {}'.format((end-start)/len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, filenames = load_images_from_folder('./data/indoor3/')\n",
    "print('processing {} images'.format(len(imgs)))\n",
    "i=0\n",
    "start = time.time()\n",
    "\n",
    "for img, filename in zip(imgs, filenames):\n",
    "    print('===============File: {} ============'.format(filename))\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    path, result_img, result_birdview, segmented_img = nav.global_planner_step(img, None)\n",
    "    \n",
    "    h,w,_ = result_img.shape\n",
    "    result_birdview = cv2.resize(result_birdview, (h,h), interpolation = cv2.INTER_AREA)\n",
    "    segmented_img = cv2.resize(segmented_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concat = cv2.hconcat([segmented_img, result_img, result_birdview])\n",
    "#     fig, ax = plt.subplots(figsize=(14, 7))\n",
    "#     ax.imshow(concat)\n",
    "#     plt.show()   \n",
    "    concat = cv2.cvtColor(concat, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imwrite('./output/indoor3/{}'.format(filename), concat)\n",
    "    i = i+1\n",
    "end = time.time()\n",
    "print('avg time: {}'.format((end-start)/len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, filenames = load_images_from_folder('./data/jackal_cam/jackal_cam_indoors1')\n",
    "print('processing {} images'.format(len(imgs)))\n",
    "i=0\n",
    "start = time.time()\n",
    "\n",
    "for img, filename in zip(imgs, filenames):\n",
    "    print('===============File: {} ============'.format(filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    path, result_img, result_birdview, segmented_img = nav.global_planner_step(img, None)\n",
    "    \n",
    "    h,w,_ = result_img.shape\n",
    "    result_birdview = cv2.resize(result_birdview, (h,h), interpolation = cv2.INTER_AREA)\n",
    "    segmented_img = cv2.resize(segmented_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    concat = cv2.hconcat([segmented_img, result_img, result_birdview])\n",
    "#     fig, ax = plt.subplots(figsize=(14, 7))\n",
    "#     ax.imshow(concat)\n",
    "#     plt.show()   \n",
    "    concat = cv2.cvtColor(concat, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imwrite('./output/out/{}'.format(filename), concat)\n",
    "    i = i+1\n",
    "end = time.time()\n",
    "print('avg time: {}'.format((end-start)/len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from object_detection import ObjectDetector\n",
    "from fchardnet_segmentation import FCHarDNetSemanticSegmentation\n",
    "from helpers import warped2scan, warp_driveable, get_driveable_mask,get_driveable_mask2\n",
    "import math\n",
    "from collections import deque\n",
    "%matplotlib inline\n",
    "FORWARD_WEIGHT = 3.0\n",
    "CENTER_WEIGHT = 0.5\n",
    "HEIGHT=480\n",
    "WIDTH=480\n",
    "OSCILLATIONS_DETECTION_LENGTH = 3\n",
    "PIXEL_PER_METER_X = (WIDTH - 2*150)/3.0 #Horizontal distance between src points in the real world ( I assumed 3.0 meters)\n",
    "PIXEL_PER_METER_Y = (HEIGHT - 20-55)/6.0 #Vertical distance between src points in the real world ( I assumed 6.0 meters)\n",
    "HORIZ_ANGLE_THRESHOLD = 15*math.pi/180.0\n",
    "AVG_SIDEWALK_WIDTH = round(3.9*PIXEL_PER_METER_X)\n",
    "\n",
    "\n",
    "class PerceptionSystem(object):\n",
    "    def __init__(self): \n",
    "        # Load Models\n",
    "        segmentation_model_path = os.path.join('/usr/src/app/dev_ws/src/vision/vision', 'pretrained', 'hardnet70_cityscapes_model.pkl')\n",
    "        self.seg_model_ = FCHarDNetSemanticSegmentation(segmentation_model_path)\n",
    "        self.object_detector_ = ObjectDetector()\n",
    "        \n",
    "        # Load perspective transforms\n",
    "        mtxs = np.load('/usr/src/app/dev_ws/src/vision/vision/PerspectiveTransform.npz')\n",
    "        self.M_ = mtxs['M']\n",
    "        self.M_inv_ = mtxs['M_inv']\n",
    "        \n",
    "        # Test Detection Models\n",
    "        print('Segmentation and Detection Models loaded, Testing the models')\n",
    "        img = cv2.imread(\"./data/73.png\")\n",
    "        self.h_orig_, self.w_orig_,_ = img.shape\n",
    "        _, _ = self.seg_model_.process_img_driveable(img,[self.h_orig_,self.w_orig_])\n",
    "        _ = self.object_detector_.process_frame(img)\n",
    "        self.im_hw_ = self.object_detector_.im_hw\n",
    "        print('Imgs tested')\n",
    "        \n",
    "    def get_driveable(self, driveable_decoded):\n",
    "        h,w,_ = driveable_decoded.shape\n",
    "        # Warp driveable area\n",
    "        warped = cv2.warpPerspective(driveable_decoded, self.M_, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "        # Calculate robot center\n",
    "        original_center = np.array([[[w/2,h]]],dtype=np.float32)\n",
    "        warped_center = cv2.perspectiveTransform(original_center, self.M_)[0][0]    \n",
    "        driveable_contour_mask = get_driveable_mask2(warped, warped_center)\n",
    "        return driveable_contour_mask\n",
    "    \n",
    "    def add_detections_birdview(self, preds, driveable_mask):\n",
    "        h,w,_ = self.object_detector_.im_hw\n",
    "        h_rate = self.h_orig_/h\n",
    "        w_rate = self.w_orig_/w\n",
    "        for pred in preds:\n",
    "            if(pred[4] > self.object_detector_.conf_thres): # If prediction has a bigger confidence than the threshold\n",
    "                x = w_rate*(pred[0]+pred[2])/2.0 # Ground middle point\n",
    "                y = h_rate*pred[3]\n",
    "                if(pred[5]==0): #person\n",
    "                    wr = 20\n",
    "                    hr = 20\n",
    "                    color = 150\n",
    "                else:\n",
    "                    wr = 20\n",
    "                    hr = 40\n",
    "                    color = 150\n",
    "                pos_orig = np.array([[[x,y]]],dtype=np.float32)\n",
    "                warped_birdview = cv2.perspectiveTransform(pos_orig, self.M_)[0][0] # Transform middle ground point to birdview\n",
    "                warped_birdview = np.uint16(warped_birdview)\n",
    "                cv2.rectangle(driveable_mask, (warped_birdview[0] -int(wr/2), warped_birdview[1]-int(hr/2)), (warped_birdview[0] +int(wr/2), warped_birdview[1]+int(hr/2)), color, -1) \n",
    "\n",
    "        \n",
    "    def process_frame(self,img):\n",
    "        # Semantic Segmentation\n",
    "        img_test = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_decoded, driveable_decoded = self.seg_model_.process_img_driveable(img_test,[self.h_orig_,self.w_orig_])\n",
    "        \n",
    "        # Get bird eye view with driveable area limits\n",
    "        driveable_mask  = self.get_driveable(driveable_decoded)\n",
    "        \n",
    "        # Object Detection\n",
    "        preds = self.object_detector_.process_frame(img)\n",
    "        \n",
    "        # Add Detections to birdview image\n",
    "        driveable_mask_with_objects = driveable_mask.copy()\n",
    "        self.add_detections_birdview(preds, driveable_mask_with_objects)\n",
    "        \n",
    "        return driveable_mask, preds, driveable_mask_with_objects\n",
    "        \n",
    "class CostMap(object):\n",
    "    def __init__(self, M):\n",
    "        # Temporary\n",
    "        self.M_ = M\n",
    "        self.h_orig_ = 720\n",
    "        self.w_orig_ = 1080\n",
    "        \n",
    "    def calculate_costmap(self,driveable_mask, preds, driveable_mask_with_objects):\n",
    "        \n",
    "        \n",
    "        # Find sidewalk edge lines and angle\n",
    "        # h,w = driveable_mask.shape\n",
    "        angle_avg, m_avg, b_avg = self.sidewalk_lines(driveable_mask, driveable_mask_with_objects) #driveable_mask_with_objects contains all objects and lines\n",
    "        \n",
    "        ## Find distance to center cost\n",
    "        cost_center = self.center_cost(m_avg,b_avg)\n",
    "\n",
    "        # Create obstacle cost map\n",
    "        cost_obst = self.obstacle_cost(driveable_mask_with_objects)\n",
    "\n",
    "        # Create inclination plane (forward cost)\n",
    "        cost_forward = self.forward_cost(angle_avg)\n",
    "\n",
    "        # Total cost\n",
    "        cost_fcn = cost_obst+cost_forward*FORWARD_WEIGHT+cost_center*CENTER_WEIGHT\n",
    "        \n",
    "        return cost_fcn, cost_obst\n",
    "        \n",
    "\n",
    "    def gaus2d(self, x=0, y=0, mx=0, my=0, sx=1, sy=1):\n",
    "        return 1. / (2. * np.pi * sx * sy) * np.exp(-((x - mx)**2. / (2. * sx**2.) + (y - my)**2. / (2. * sy**2.)))\n",
    "    \n",
    "    def obstacle_cost(self, mask_with_objects, gaussian_shape = 150):\n",
    "        x = np.linspace(-2, 2,gaussian_shape)\n",
    "        y = np.linspace(-2, 2,gaussian_shape*2)\n",
    "        x, y = np.meshgrid(x, y) # get 2D variables instead of 1D\n",
    "        z = self.gaus2d(x, y)\n",
    "        z = np.float32(z)\n",
    "        cost_obst = cv2.filter2D(mask_with_objects,-1,z)\n",
    "        cost_obst/=np.amax(cost_obst)\n",
    "        return cost_obst\n",
    "\n",
    "    def forward_cost(self, angle):\n",
    "        normal = np.array([math.tan(-angle),-1,HEIGHT])\n",
    "        point = np.array([WIDTH/2, HEIGHT, 0])\n",
    "        d = -np.sum(point*normal)# dot product\n",
    "        xx, yy = np.meshgrid(range(WIDTH), range(HEIGHT))\n",
    "        cost_forward = (-normal[0]*xx - normal[1]*yy - d)*1./normal[2]\n",
    "        return cost_forward\n",
    "\n",
    "    def center_cost(self, m,b):\n",
    "        if m is not None:\n",
    "            xx, yy = np.meshgrid(range(WIDTH), range(HEIGHT))\n",
    "            cost_center = abs(-m*xx+yy-b)/math.sqrt(m**2+1)\n",
    "        else:\n",
    "            cost_center = np.zeros((WIDTH,HEIGHT))\n",
    "        return cost_center/np.amax(cost_center)\n",
    "\n",
    "\n",
    "   \n",
    "    def sidewalk_lines(self, mask, mask_out):\n",
    "        mask = np.uint8(mask)\n",
    "        \n",
    "        # Detect lines in driveable area mask\n",
    "        lines = cv2.HoughLinesP(mask, 1, 1*np.pi / 180, 100, None, 150, 50)\n",
    "\n",
    "        line_angles = []\n",
    "        lines_left = []\n",
    "        lines_right = []\n",
    "        lines_found = True\n",
    "        if(lines is not None):\n",
    "            for line in lines:\n",
    "                x2,y2,x1,y1 = line[0]\n",
    "                # Calculate angle, checking which y-coordinate is higher\n",
    "                if(y2<y1): angle = -math.atan2(y2-y1,x2-x1)-math.pi/2\n",
    "                else: angle = -math.atan2(y1-y2,x1-x2)-math.pi/2\n",
    "                line_angles.append(angle)\n",
    "                    \n",
    "                # Detect horizontal lines corresponding to the corners\n",
    "                if(abs(angle-math.pi/2) < HORIZ_ANGLE_THRESHOLD):\n",
    "                    cv2.line(mask_out,(round(x1),round(y1)),(round(x2),round(y2)),100,1)\n",
    "\n",
    "                # Detect coordinate at the bottom of image\n",
    "                if(x2 == x1): x2 += 1 # Avoid dividing by 0\n",
    "                if(y2 == y1): y2 += 1 # Avoid dividing by 0\n",
    "                    \n",
    "                m = (y2-y1)/(x2-x1)\n",
    "                b = y1-m*x1\n",
    "                x3 = round((HEIGHT-b)/m)\n",
    "                x1 = x3\n",
    "                y1 = HEIGHT\n",
    "\n",
    "                # Add lines to the left and right list\n",
    "                if(x3<WIDTH/2):\n",
    "                    lines_left.append([m,b,x2,y2,x1,y1])\n",
    "                else:\n",
    "                    lines_right.append([m,b,x2,y2,x1,y1])\n",
    "    #         print('lines_left: {}'.format(np.array(lines_left)))\n",
    "    #         print('lines_right: {}'.format(np.array(lines_right)))\n",
    "            lines_left = np.array(lines_left)\n",
    "            lines_right = np.array(lines_right)\n",
    "\n",
    "            # Find average line left and right\n",
    "            if(len(lines_left)>0):\n",
    "                m_avg_left = np.average(lines_left[:,0])\n",
    "                b_avg_left = np.average(lines_left[:,1])\n",
    "                y1_left = np.amin(lines_left[:,3])\n",
    "                x1_left = (y1_left - b_avg_left) / m_avg_left\n",
    "                x2_left = (HEIGHT-b_avg_left) / m_avg_left\n",
    "                if x2_left > 0 and x2_left < WIDTH:\n",
    "                    y2_left = HEIGHT\n",
    "                else:\n",
    "                    x2_left = 0\n",
    "                    y2_left = b_avg_left\n",
    "                    \n",
    "                if (len(lines_right) > 0): # both lines are found\n",
    "                    m_avg_right = np.average(lines_right[:,0])\n",
    "                    b_avg_right = np.average(lines_right[:,1])\n",
    "                    y1_right = np.amin(lines_right[:,3])\n",
    "                    x1_right = (y1_right - b_avg_right) / m_avg_right\n",
    "                    x2_right = (HEIGHT-b_avg_right) / m_avg_right\n",
    "                    if x2_right > 0 and x2_left < WIDTH:\n",
    "                        y2_right = HEIGHT\n",
    "                    else:\n",
    "                        x2_right = 0\n",
    "                        y2_right = b_avg_right\n",
    "                else:\n",
    "                    print('right line not found, adding it')\n",
    "                    m_avg_right = m_avg_left  \n",
    "                    b_avg_right = AVG_SIDEWALK_WIDTH*math.sqrt(m_avg_right**2+1)+b_avg_left\n",
    "                    if((b_avg_right - b_avg_left) < 0):\n",
    "                        b_avg_right = -AVG_SIDEWALK_WIDTH*math.sqrt(m_avg_right**2+1)+b_avg_left\n",
    "                    y1_right = y1_left\n",
    "                    x1_right = (y1_right - b_avg_right) / m_avg_right\n",
    "                    y2_right = y2_left\n",
    "                    x2_right = (y2_right - b_avg_right) / m_avg_right\n",
    "            else:\n",
    "                if (len(lines_right) > 0): # only right line found\n",
    "                        \n",
    "                    m_avg_right = np.average(lines_right[:,0])\n",
    "                    b_avg_right = np.average(lines_right[:,1])\n",
    "                    y1_right = np.amin(lines_right[:,3])\n",
    "                    x1_right = (y1_right - b_avg_right) / m_avg_right\n",
    "                    x2_right = (HEIGHT-b_avg_right) / m_avg_right\n",
    "                    if x2_right > 0 and x2_right < WIDTH:\n",
    "                        y2_right = HEIGHT\n",
    "                    else:\n",
    "                        x2_right = 0\n",
    "                        y2_right = b_avg_right\n",
    "                    m_avg_left = m_avg_right  \n",
    "                    b_avg_left = -AVG_SIDEWALK_WIDTH*math.sqrt(m_avg_left**2+1)+b_avg_right\n",
    "                    if((b_avg_left - b_avg_right) < 0):\n",
    "        #                 print(\"si\")\n",
    "                        b_avg_left = AVG_SIDEWALK_WIDTH*math.sqrt(m_avg_right**2+1)+b_avg_right\n",
    "                    y1_left = y1_right\n",
    "                    x1_left = (y1_left - b_avg_left) / m_avg_left\n",
    "                    y2_left = y2_right\n",
    "                    x2_left = (y2_left - b_avg_left) / m_avg_left\n",
    "                else:\n",
    "                    angle_avg = 0\n",
    "                    lines_found = False\n",
    "        else:\n",
    "            lines_found = False\n",
    "        angle_avg = np.average(line_angles)\n",
    "\n",
    "        if(lines_found):\n",
    "    #         print([x1_right, y1_right, x2_right, y2_right])\n",
    "    #         print([x1_left, y1_left, x2_left, y2_left])\n",
    "            angle_left = -math.atan2(y2_left-y1_left,x2_left-x1_left)-math.pi/2\n",
    "            angle_right = -math.atan2(y2_right-y1_right,x2_right-x1_right)-math.pi/2\n",
    "\n",
    "            cv2.line(mask_out,(round(x1_left),round(y1_left)),(round(x2_left),round(y2_left)),200,3)\n",
    "            cv2.line(mask_out,(round(x1_right),round(y1_right)),(round(x2_right),round(y2_right)),200,3)\n",
    "            # Calculate middle line\n",
    "            angle_avg = (angle_left + angle_right) / 2.0\n",
    "            m_avg = math.tan(-angle_avg+math.pi/2.0)\n",
    "            x_center = ( x2_left + x2_right ) / 2.0\n",
    "            b_avg = HEIGHT - m_avg*x_center\n",
    "        else:\n",
    "            m_avg = None\n",
    "            b_avg = None\n",
    "        return angle_avg, m_avg, b_avg\n",
    "                          \n",
    "\n",
    "class PotentialFieldPlanner(object):\n",
    "                          \n",
    "    def __init__(self, M_inv):\n",
    "        self.M_inv_ = M_inv\n",
    "        print(\"Planner\")\n",
    "                         \n",
    "    def get_motion_model(self):\n",
    "        # dx, dy\n",
    "        motion = [\n",
    "    #               [1, 0], #right\n",
    "    #               [0, 2], #back\n",
    "    #               [-1, 0], #left\n",
    "                  [0, -4], # front\n",
    "                  [-1, -4],#front-left\n",
    "                  [-2, -4],#front-left\n",
    "                  [-3, -4],#front-left\n",
    "                  [-4, -4],#front-left\n",
    "    #               [-1, 2], # back-left\n",
    "                  [1, -4], #front-right\n",
    "                  [2, -4], #front-right\n",
    "                  [3, -4], #front-right\n",
    "                  [4, -4], #front-right\n",
    "    #               [1, 1]  #back-right\n",
    "                  ]\n",
    "        return motion\n",
    "\n",
    "    def oscillations_detection(self,previous_ids, ix, iy):\n",
    "        previous_ids.append((ix, iy))\n",
    "        if (len(previous_ids) > OSCILLATIONS_DETECTION_LENGTH):\n",
    "            previous_ids.popleft()\n",
    "        # check if contains any duplicates by copying into a set\n",
    "        previous_ids_set = set()\n",
    "        for index in previous_ids:\n",
    "            if index in previous_ids_set:\n",
    "                return True\n",
    "            else:\n",
    "                previous_ids_set.add(index)\n",
    "        return False\n",
    "\n",
    "    def calculate_path(self,pmap):\n",
    "        output = pmap.copy()*0\n",
    "        motion = self.get_motion_model()\n",
    "        previous_ids = deque()\n",
    "        ix = round(WIDTH/2)\n",
    "        iy = round(HEIGHT) \n",
    "        path = []\n",
    "        while(ix > 5 and iy > 50 and ix< WIDTH-5):\n",
    "            minp = float(\"inf\")\n",
    "            minix, miniy = 0, -1\n",
    "            for i, _ in enumerate(motion):\n",
    "                inx = int(ix + 1*motion[i][0])\n",
    "                iny = int(iy + 1*motion[i][1])\n",
    "                if inx >= WIDTH or iny >= HEIGHT or inx < 0 or iny < 0:\n",
    "                    p = float(\"inf\")  # outside area\n",
    "                    print(\"outside potential!\")\n",
    "                else:\n",
    "                    p = pmap[iny][inx]\n",
    "\n",
    "                if minp >= p:\n",
    "                    min_motion = motion[i]\n",
    "                    minp = p\n",
    "                    minix = inx\n",
    "                    miniy = iny\n",
    "            ix = minix\n",
    "            iy = miniy\n",
    "            # Calculate points\n",
    "            px = (ix-WIDTH/2)/PIXEL_PER_METER_X\n",
    "            py = (HEIGHT-iy)/PIXEL_PER_METER_Y\n",
    "            path.append([px,py])\n",
    "            if (self.oscillations_detection(previous_ids, ix, iy)):\n",
    "                print(\"Oscillation detected at ({},{})!\".format(ix, iy))\n",
    "                break\n",
    "            cv2.circle(output, (ix, iy),int(3.0),1, -1)\n",
    "        return np.array(path),output\n",
    "\n",
    "    def draw_result(self, img, cost_obst, path_img):\n",
    "        h_orig,w_orig,_ = img.shape\n",
    "\n",
    "        result_birdview = cv2.merge([cost_obst, path_img, cost_obst*0])\n",
    "        result_birdview = np.uint8(result_birdview*255.0)\n",
    "        unwarped_birdview = cv2.warpPerspective(result_birdview, self.M_inv_, (w_orig,h_orig), flags=cv2.INTER_LINEAR)\n",
    "    #     unwarped_birdview = np.uint8(unwarped_birdview*255.0)\n",
    "        output = cv2.addWeighted(img, 0.7, unwarped_birdview, 0.5, 0)    \n",
    "        return output, result_birdview\n",
    "\n",
    "class NavigationSystem(object):\n",
    "    def __init__(self): \n",
    "        self.perception_ = PerceptionSystem()\n",
    "        self.costmap_ = CostMap(self.perception_.M_)\n",
    "        self.planner_ = PotentialFieldPlanner(self.perception_.M_inv_)\n",
    "\n",
    "    def path_planning(self, img):\n",
    "        driveable_mask, preds, driveable_mask_with_objects = self.perception_.process_frame(img)\n",
    "        cost,cost_obst = self.costmap_.calculate_costmap(driveable_mask, preds, driveable_mask_with_objects)\n",
    "        path, path_img = self.planner_.calculate_path(cost)\n",
    "        result_img, result_birdview = self.planner_.draw_result(img, cost_obst, path_img)\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        ax.imshow(result_img)\n",
    "        plt.show()\n",
    "#     def seg2scan(self, driveable_area):\n",
    "#         h,w,_ = driveable_area.shape\n",
    "#         warped = cv2.warpPerspective(driveable_area, M, (480, 480), flags=cv2.INTER_LINEAR)\n",
    "#         original_center = np.array([[[w/2,h]]],dtype=np.float32)\n",
    "#         warped_center = cv2.perspectiveTransform(original_center, M)[0][0]\n",
    "#         scan_distances, angle_increment, warped_contours = warped2scan(warped, warped_center)\n",
    "#         return warped, warped_contours, scan_distances, angle_increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "nav = NavigationSystem()\n",
    "img = cv2.imread(\"./data/75.png\")\n",
    "# img = cv2.imread(\"./data/195.png\")\n",
    "h_orig,w_orig,_ = img.shape\n",
    "\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "start = time.time()\n",
    "nav.path_planning(img)\n",
    "end = time.time()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
